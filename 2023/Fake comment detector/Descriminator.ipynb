{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(sequence, max_length, pad_token_id):\n",
        "    \"\"\"\n",
        "    주어진 sequence를 max_length로 패딩하는 함수\n",
        "\n",
        "    input:\n",
        "    - sequence (Tensor): input sequence\n",
        "    - max_length (int): 최대로 패딩할 길이\n",
        "    - pad_token_id (int): 패딩에 사용할 토큰의 인덱스\n",
        "\n",
        "    output:\n",
        "    - padded_sequence (Tensor): 패딩된 sequence\n",
        "    \"\"\"\n",
        "    padding_length = max_length - len(sequence)\n",
        "\n",
        "    if padding_length > 0:\n",
        "        padded_sequence = F.pad(sequence, (0, padding_length), value=pad_token_id)\n",
        "    else:\n",
        "        padded_sequence = sequence\n",
        "\n",
        "    return padded_sequence"
      ],
      "metadata": {
        "id": "vqBnd9iIrqjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYqi0lO4rHOR"
      },
      "outputs": [],
      "source": [
        "# 판별 함수\n",
        "def discriminate_sentence(discriminator, sentence, tokenizer, max_length=50):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \"\"\"\n",
        "    주어진 문장을 판별하는 함수\n",
        "\n",
        "    input:\n",
        "    - sentence : 문장\n",
        "\n",
        "    output:\n",
        "    - real or fake prob\n",
        "    \"\"\"\n",
        "    inputs = tokenizer.encode(real_data, return_tensors='pt', truncation=True, padding=True, max_length=max_length)\n",
        "    inputs = pad_sequence(input_ids[0], max_length, tokenizer.pad_token_id)\n",
        "    inputs = inputs.to(device).float()\n",
        "    output = discriminator(inputs)\n",
        "    return output.item()  # 0부터 1까지의 값, 0에 가까울수록 가짜, 1에 가까울수록 진짜"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "discriminator = discriminator.to(device)\n",
        "pretrained_model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name)\n",
        "# 판별 함수를 사용하여 새로운 문장 판별\n",
        "input_sentence = \"John scratched his arm and the boy who knew Mary scratched her arm..\"\n",
        "discriminator = torch.load('/your_dir/discriminator.pt')\n",
        "discriminator.eval()  # 평가 모드로 전환\n",
        "result = discriminate_sentence(discriminator, input_sentence, tokenizer)\n",
        "\n",
        "print(f\"The sentence is {(1-result)*100:.2f}% fake and {result*100:.2f}% real.\")"
      ],
      "metadata": {
        "id": "B4fHHmuIsAzj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}